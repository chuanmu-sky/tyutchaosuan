import torch

# x的形状是(3,4)
x = [[1, 2, 4, 1],
     [6, 3, 2, 4],
     [2, 4, 6, 1]]
x = torch.tensor(x, dtype=torch.float32)
# 参数是(N,D)中的D
LN_1d = torch.nn.LayerNorm(4)
x = LN_1d(x)
# 输出结果是对D上的数据进行了LN操作, 也就是横向的每一组数据是正态分布的, 一共N组
print(x)


# x的形状是(3,4,5)
x = [[[1,2,4,1,3],
      [2,5,3,7,8],
      [4,7,2,1,0],
      [9,5,2,1,7]],
     
     [[3,6,4,0,7],
      [2,1,6,3,8],
      [9,0,3,1,5],
      [5,5,6,1,2]],
     
     [[4,2,6,9,0],
      [1,0,2,5,8],
      [3,7,2,1,9],
      [0,1,0,2,3]]]
x = torch.tensor(x,dtype=torch.float32)
# 参数是(B,N,D)中的(N,D)
LN_2d = torch.nn.LayerNorm((4,5))
x = LN_2d(x)
# 输出结果是对(N,D)上的数据进行了LN操作, 也就是每个(N,D)矩阵是正态分布的, 一共B组
print(x)


# 总结LN可以对2d和3d(也可以更多，但是目前只用到这两个)的数据进行正则化操作
# 对(N,D), 参数是D, 生成形状是(D,)的正态分布, 一共N组
# 对(B,N,D), 参数是(N,D), 生成形状是(N,D)的正态分布, 一共B组
